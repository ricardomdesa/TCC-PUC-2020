{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analise modelos ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregar dados tratados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install seaborn\n",
    "# ! pip install plotly\n",
    "# ! pip install statsmodels\n",
    "# ! pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, precision_score\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def carregar_joblib(file_name: str = \"../out/result_analise_desc_scaled.joblib\"):\n",
    "    df = joblib.load(file_name)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_feature_selection_extra_trees(df):\n",
    "    modelo = ExtraTreesClassifier(random_state=1)\n",
    "    x = df.drop(\"decisao\", axis=1)\n",
    "    y = df[\"decisao\"]\n",
    "    modelo.fit(x, y)\n",
    "\n",
    "    caracteristicas_importantes = pd.DataFrame(modelo.feature_importances_, x.columns).sort_values(by=0, ascending=False)\n",
    "    print(caracteristicas_importantes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ajustar_scaler(tabela_original):\n",
    "    scaler = StandardScaler()\n",
    "    tabela_auxiliar = tabela_original.drop(\"decisao\", axis=1)\n",
    "    \n",
    "    tabela_auxiliar = pd.DataFrame(scaler.fit_transform(tabela_auxiliar), tabela_auxiliar.index, tabela_auxiliar.columns)\n",
    "    tabela_auxiliar[\"decisao\"] = tabela_original[\"decisao\"]\n",
    "    \n",
    "    return tabela_auxiliar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dados(df):\n",
    "    X = df.drop([\"decisao\"], axis=1)\n",
    "    y = df[\"decisao\"]\n",
    "\n",
    "    X_treino, X_teste, y_treino, y_teste = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    print(f\"{len(X_treino)=} {len(X_teste)=} {len(y_treino)=} {len(y_teste)=}\")\n",
    "\n",
    "    return X_treino, X_teste, y_treino, y_teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy selection para avaliar uma selecao randomica de compra e venda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_dummy_classifier(\n",
    "    X_treino,\n",
    "    X_teste, \n",
    "    y_treino\n",
    "):\n",
    "    dummy = DummyClassifier(strategy=\"stratified\", random_state=2)\n",
    "    dummy.fit(X_treino, y_treino)\n",
    "    previsao_dummy = dummy.predict(X_teste)\n",
    "    \n",
    "    return previsao_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avaliar(y_teste, previsoes, nome_modelo):\n",
    "    print(nome_modelo)\n",
    "    report = classification_report(y_teste, previsoes)\n",
    "    print(report)\n",
    "    cf_matrix = pd.DataFrame(confusion_matrix(y_teste, previsoes), index=[\"Vender\", \"Comprar\"], columns=[\"Vender\", \"Comprar\"])\n",
    "    sns.heatmap(cf_matrix, annot=True, cmap=\"Blues\", fmt=',')\n",
    "    plt.show()\n",
    "    print(\"#\" * 50)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos a serem testados\n",
    "\n",
    "- AdaBoost\n",
    "- Decision Tree\n",
    "- Random Forest\n",
    "- ExtraTree\n",
    "- Gradient Boost\n",
    "- K Nearest Neighbors (KNN)\n",
    "- Logistic Regression\n",
    "- Rede Neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def definir_modelos_ml() -> dict:\n",
    "    return {\n",
    "        \"XGBoost\": XGBClassifier(max_depth=9, scale_pos_weight=0.2),\n",
    "        \"AdaBoost\": AdaBoostClassifier(random_state=42),\n",
    "        \"DecisionTree\": DecisionTreeClassifier(random_state=42),\n",
    "        \"RandomForest\": RandomForestClassifier(random_state=42),\n",
    "        \"ExtraTree\": ExtraTreesClassifier(random_state=42),\n",
    "        \"GradientBoost\": GradientBoostingClassifier(random_state=42),\n",
    "        # \"KNN\": KNeighborsClassifier(),\n",
    "        # \"LogisticRegression\": LogisticRegression(C=1.0, max_iter=100, tol=0.0001, random_state=1, solver=\"newton-cg\",\n",
    "        #                         fit_intercept=True, intercept_scaling=1, l1_ratio=None, penalty=\"none\", warm_start=False),\n",
    "        # \"LogisticRegression\": LogisticRegression(C=1.0, max_iter=100, tol=0.0001, random_state=1, solver=\"newton-cg\"),\n",
    "        # \"LogisticRegression\": LogisticRegression(random_state=42),\n",
    "        # \"RedeNeural\": MLPClassifier(random_state= 42),\n",
    "        # \"RedeNeural\": MLPClassifier(solver= \"sgd\", random_state= 2, hidden_layer_sizes= 5),\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rodar_imprimir_modelos_ml(modelos, X_treino, X_teste, y_treino, y_teste):\n",
    "    for nome_modelo in modelos:\n",
    "        modelo = modelos[nome_modelo]\n",
    "        modelo.fit(X_treino, y_treino)\n",
    "        previsoes = modelo.predict(X_teste)\n",
    "        avaliar(y_teste, previsoes, nome_modelo)\n",
    "        modelos[nome_modelo] = modelo\n",
    "    \n",
    "    return modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execucao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Session cannot generate requests",
     "output_type": "error",
     "traceback": [
      "Error: Session cannot generate requests",
      "at w.executeCodeCell (/Users/shopee/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:301180)",
      "at w.execute (/Users/shopee/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:300551)",
      "at w.start (/Users/shopee/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:296215)",
      "at processTicksAndRejections (internal/process/task_queues.js:93:5)",
      "at async t.CellExecutionQueue.executeQueuedCells (/Users/shopee/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:310950)",
      "at async t.CellExecutionQueue.start (/Users/shopee/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:310490)"
     ]
    }
   ],
   "source": [
    "def main(scaled: bool):\n",
    "    if scaled:\n",
    "        df = carregar_joblib(\"../out/result_analise_desc_scaled.joblib\")\n",
    "        print(\"scaled df\")\n",
    "    else:\n",
    "        df = carregar_joblib()\n",
    "        print(\"NOT scaled df\")\n",
    "\n",
    "    print(df.shape)\n",
    "    print(df.columns)\n",
    "\n",
    "    # split database train and test\n",
    "    X_treino, X_teste, y_treino, y_teste = split_dados(df)\n",
    "\n",
    "    # Run a dummy predict classifier\n",
    "    # dummy_predict = run_dummy_classifier(X_treino, X_teste, y_treino)\n",
    "\n",
    "    # print dummy results\n",
    "    # avaliar(y_teste, dummy_predict, \"Dummy\")\n",
    "\n",
    "    modelos = definir_modelos_ml()\n",
    "\n",
    "    modelos = rodar_imprimir_modelos_ml(modelos, X_treino, X_teste, y_treino, y_teste)\n",
    "\n",
    "    return df\n",
    "\n",
    "df = main(scaled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Session cannot generate requests",
     "output_type": "error",
     "traceback": [
      "Error: Session cannot generate requests",
      "at w.executeCodeCell (/Users/shopee/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:301180)",
      "at w.execute (/Users/shopee/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:300551)",
      "at w.start (/Users/shopee/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:296215)",
      "at processTicksAndRejections (internal/process/task_queues.js:93:5)",
      "at async t.CellExecutionQueue.executeQueuedCells (/Users/shopee/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:310950)",
      "at async t.CellExecutionQueue.start (/Users/shopee/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:310490)"
     ]
    }
   ],
   "source": [
    "# df = main(scaled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = main(scaled=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Em comparacao entre dados com tratamento de standardScaler e sem, notou-se uma precisao melhor quando os dados nao estao com scaler para KNN e Rede Neural."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escolha de 3 melhores modelos para comparação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def run_tunning_grid(X_treino, y_treino):\n",
    "\n",
    "    n_estimators = range(100, 300, 100)\n",
    "    max_features = list(range(1, 7))\n",
    "    max_features = [4,5,7]\n",
    "    max_features = [\"auto\", \"sqrt\", \"log2\"]\n",
    "    # max_features.append(\"auto\")\n",
    "\n",
    "    precision2_score = make_scorer(precision_score, labels=[2], average='macro')\n",
    "    parameters = {\n",
    "        \"loss\":[\"deviance\"],\n",
    "        \"learning_rate\": [0.01, 0.025, 0.05, 0.075, 0.1, 0.15, 0.2],\n",
    "        \"min_samples_split\": [0.05, 0.1, 0.2], #np.linspace(0.05, 0.1, 0.2),\n",
    "        \"min_samples_leaf\": [0.05, 0.1, 0.2], #np.linspace(0.05, 0.1, 0.2),\n",
    "        \"max_depth\":[3],\n",
    "        \"max_features\":[\"log2\", \"sqrt\"],\n",
    "        \"criterion\": [\"mae\"],\n",
    "        # \"subsample\":[0.5, 0.618, 0.8, 0.85, 0.9, 0.95, 1.0],\n",
    "        \"n_estimators\":[7]\n",
    "        }\n",
    "    grid = GridSearchCV(\n",
    "            estimator=GradientBoostingClassifier(random_state=1),\n",
    "            param_grid=parameters,\n",
    "            scoring=precision2_score,\n",
    "            refit=False,cv=10, n_jobs=-1\n",
    "    )\n",
    "\n",
    "    return grid.fit(X_treino, y_treino)   "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8ab34ce4145f682337f5fa161ec816727aecde41915875d0a837a5ffe57556a8"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('TCC_PUC': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
